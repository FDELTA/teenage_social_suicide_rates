{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "#Supervised\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.svm import LinearSVC\n",
    "import pickle\n",
    "#Unsupervised\n",
    "# Deep Learning\n",
    "import torch\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>procesado</th>\n",
       "      <th>Polaridad</th>\n",
       "      <th>Subjetividad</th>\n",
       "      <th>palabras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negativa</td>\n",
       "      <td>2014943573</td>\n",
       "      <td>Wed Jun 03 03:11:56 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bexodus</td>\n",
       "      <td>@MissScion Fell asleep around 9p last night wo...</td>\n",
       "      <td>['fell', 'asleep', 'around', 'last', 'night', ...</td>\n",
       "      <td>-0.016667</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>1971796339</td>\n",
       "      <td>Sat May 30 07:55:06 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>sazmataz_x</td>\n",
       "      <td>@katie_andhearts going in town later to get my...</td>\n",
       "      <td>['going', 'town', 'late', 'get', 'prom', 'shoe...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>1978132662</td>\n",
       "      <td>Sat May 30 22:31:29 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Deasoy</td>\n",
       "      <td>happy day</td>\n",
       "      <td>['happy', 'day']</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negativa</td>\n",
       "      <td>1679901725</td>\n",
       "      <td>Sat May 02 10:26:43 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>SashaPanda</td>\n",
       "      <td>Tummy Hurts  Stupid Stress</td>\n",
       "      <td>['tummy', 'hurts', 'stupid', 'stress']</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>2055154954</td>\n",
       "      <td>Sat Jun 06 08:48:06 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LianeGentrySkye</td>\n",
       "      <td>@jodywallace  Are you at the LF event?  I have...</td>\n",
       "      <td>['event', 'seen']</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target         ids                          date      flag  \\\n",
       "0  Negativa  2014943573  Wed Jun 03 03:11:56 PDT 2009  NO_QUERY   \n",
       "1  Positiva  1971796339  Sat May 30 07:55:06 PDT 2009  NO_QUERY   \n",
       "2  Positiva  1978132662  Sat May 30 22:31:29 PDT 2009  NO_QUERY   \n",
       "3  Negativa  1679901725  Sat May 02 10:26:43 PDT 2009  NO_QUERY   \n",
       "4   Neutral  2055154954  Sat Jun 06 08:48:06 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \\\n",
       "0          bexodus  @MissScion Fell asleep around 9p last night wo...   \n",
       "1       sazmataz_x  @katie_andhearts going in town later to get my...   \n",
       "2           Deasoy                                         happy day    \n",
       "3       SashaPanda                         Tummy Hurts  Stupid Stress   \n",
       "4  LianeGentrySkye  @jodywallace  Are you at the LF event?  I have...   \n",
       "\n",
       "                                           procesado  Polaridad  Subjetividad  \\\n",
       "0  ['fell', 'asleep', 'around', 'last', 'night', ...  -0.016667      0.488889   \n",
       "1  ['going', 'town', 'late', 'get', 'prom', 'shoe...   0.250000      0.650000   \n",
       "2                                   ['happy', 'day']   0.800000      1.000000   \n",
       "3             ['tummy', 'hurts', 'stupid', 'stress']  -0.800000      1.000000   \n",
       "4                                  ['event', 'seen']   0.000000      0.000000   \n",
       "\n",
       "   palabras  \n",
       "0        26  \n",
       "1        14  \n",
       "2         2  \n",
       "3         4  \n",
       "4        11  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent= pd.read_csv(\"output/final_tweets.csv\")\n",
    "sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label_enc\n",
       "0          0\n",
       "1          2\n",
       "2          2\n",
       "3          0\n",
       "4          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "sent[\"Label_enc\"] = le.fit_transform(sent[\"target\"])\n",
    "\n",
    "# Display the encoded labels\n",
    "display(sent[[\"Label_enc\"]].head())\n",
    "\n",
    "# Select the features and the target\n",
    "X = sent['procesado']\n",
    "y = sent[\"Label_enc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.715\n"
     ]
    }
   ],
   "source": [
    "tfidfstops=stopwords.words('english')\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words= tfidfstops)\n",
    "\n",
    "# Create the tf-idf vectorizer\n",
    "model_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# First fit the vectorizer with our training set\n",
    "tfidf_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Now we can fit our test data with the same vectorizer\n",
    "tfidf_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the Bernoulli Naive Bayes classifier\n",
    "nb = BernoulliNB()\n",
    "\n",
    "# Fit the model\n",
    "nb.fit(tfidf_train, y_train)\n",
    "\n",
    "# Print the accuracy score\n",
    "best_accuracy = cross_val_score(nb, tfidf_test, y_test, cv=10, scoring='accuracy').max()\n",
    "print(\"Accuracy:\",best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "Matriz 3x3 donde se ven los tweets que se catalogaron erroneamente\n",
      "\n",
      "[[230  87 108]\n",
      " [ 16 668  54]\n",
      " [ 26  52 759]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.54      0.66       425\n",
      "           1       0.83      0.91      0.86       738\n",
      "           2       0.82      0.91      0.86       837\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.83      0.78      0.80      2000\n",
      "weighted avg       0.83      0.83      0.82      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = nb.predict(tfidf_test)\n",
    "\n",
    "# Print the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix\\nMatriz 3x3 donde se ven los tweets que se catalogaron erroneamente\\n\")\n",
    "print(cm)\n",
    "\n",
    "# Print the Classification Report\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(\"\\n\\nClassification Report\\n\")\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Outputs/model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0cf3e815c374>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./Outputs/model.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Outputs/model.pkl'"
     ]
    }
   ],
   "source": [
    "pickle.dump(nb, open(\"./Outputs/model.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET\n",
    "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "TRAIN_SIZE = 0.8\n",
    "\n",
    "# TEXT CLENAING\n",
    "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "\n",
    "# WORD2VEC \n",
    "W2V_SIZE = 300\n",
    "W2V_WINDOW = 7\n",
    "W2V_EPOCH = 32\n",
    "W2V_MIN_COUNT = 10\n",
    "\n",
    "# KERAS\n",
    "SEQUENCE_LENGTH = 300\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# SENTIMENT\n",
    "POSITIVE = \"POSITIVE\"\n",
    "NEGATIVE = \"NEGATIVE\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "SENTIMENT_THRESHOLDS = (0.4, 0.7)\n",
    "\n",
    "# EXPORT\n",
    "#KERAS_MODEL = \"model.h5\"\n",
    "#WORD2VEC_MODEL = \"model.w2v\"\n",
    "#TOKENIZER_MODEL = \"tokenizer.pkl\"\n",
    "#ENCODER_MODEL = \"encoder.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN size: 8000\n",
      "TEST size: 2000\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(sent, test_size=1-TRAIN_SIZE, random_state=42)\n",
    "print(\"TRAIN size:\", len(df_train))\n",
    "print(\"TEST size:\", len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>procesado</th>\n",
       "      <th>Polaridad</th>\n",
       "      <th>Subjetividad</th>\n",
       "      <th>palabras</th>\n",
       "      <th>Label_enc</th>\n",
       "      <th>nLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>2070190399</td>\n",
       "      <td>Sun Jun 07 17:15:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Aromantic</td>\n",
       "      <td>Who needs whips &amp;amp; chains when you have cak...</td>\n",
       "      <td>['needs', 'whips', 'amp', 'chains', 'cake']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>1823352144</td>\n",
       "      <td>Sat May 16 21:44:41 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>KeedyKat</td>\n",
       "      <td>@SouthernBell07 u went to the ol' school for r...</td>\n",
       "      <td>['went', 'school', 'real', 'one', 'listening',...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>Negativa</td>\n",
       "      <td>1677113394</td>\n",
       "      <td>Sat May 02 00:30:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>love2live10101</td>\n",
       "      <td>@Traphik Aww I'm sorry! I voted for u! @annspa...</td>\n",
       "      <td>['aww', 'sorry', 'voted', 'yesterday', 'droppe...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>2178448548</td>\n",
       "      <td>Mon Jun 15 07:43:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>liannebigworld</td>\n",
       "      <td>aargh I want to go home but it's raining and I...</td>\n",
       "      <td>['aargh', 'want', 'home', 'raining', 'bring', ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>Negativa</td>\n",
       "      <td>2253553289</td>\n",
       "      <td>Sat Jun 20 08:21:43 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bahramd</td>\n",
       "      <td>I'm  so tired</td>\n",
       "      <td>['tired']</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target         ids                          date      flag  \\\n",
       "9254   Neutral  2070190399  Sun Jun 07 17:15:09 PDT 2009  NO_QUERY   \n",
       "1561  Positiva  1823352144  Sat May 16 21:44:41 PDT 2009  NO_QUERY   \n",
       "1670  Negativa  1677113394  Sat May 02 00:30:57 PDT 2009  NO_QUERY   \n",
       "6087   Neutral  2178448548  Mon Jun 15 07:43:00 PDT 2009  NO_QUERY   \n",
       "6669  Negativa  2253553289  Sat Jun 20 08:21:43 PDT 2009  NO_QUERY   \n",
       "\n",
       "                user                                               text  \\\n",
       "9254       Aromantic  Who needs whips &amp; chains when you have cak...   \n",
       "1561        KeedyKat  @SouthernBell07 u went to the ol' school for r...   \n",
       "1670  love2live10101  @Traphik Aww I'm sorry! I voted for u! @annspa...   \n",
       "6087  liannebigworld  aargh I want to go home but it's raining and I...   \n",
       "6669         bahramd                                     I'm  so tired    \n",
       "\n",
       "                                              procesado  Polaridad  \\\n",
       "9254        ['needs', 'whips', 'amp', 'chains', 'cake']        0.0   \n",
       "1561  ['went', 'school', 'real', 'one', 'listening',...        0.2   \n",
       "1670  ['aww', 'sorry', 'voted', 'yesterday', 'droppe...       -0.1   \n",
       "6087  ['aargh', 'want', 'home', 'raining', 'bring', ...        0.0   \n",
       "6669                                          ['tired']       -0.4   \n",
       "\n",
       "      Subjetividad  palabras  Label_enc  nLabel  \n",
       "9254          0.00         9          1       0  \n",
       "1561          0.30        20          2       1  \n",
       "1670          0.95        27          0      -1  \n",
       "6087          0.00        25          1       0  \n",
       "6669          0.70         3          0      -1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-d29626858213>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"nLabel\"] = train[\"target\"].apply(numerar_polaridad)\n",
      "<ipython-input-21-d29626858213>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"nLabel\"] = test[\"target\"].apply(numerar_polaridad)\n"
     ]
    }
   ],
   "source": [
    "def numerar_polaridad(polaridad):\n",
    "    if polaridad == 'Positiva':\n",
    "        return 1\n",
    "    if polaridad == \"Neutral\":\n",
    "        return 0\n",
    "    if polaridad == \"Negativa\":\n",
    "        return -1\n",
    "\n",
    "train[\"nLabel\"] = train[\"target\"].apply(numerar_polaridad)\n",
    "test[\"nLabel\"] = test[\"target\"].apply(numerar_polaridad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'ids', 'date', 'flag', 'user', 'text', 'procesado',\n",
       "       'Polaridad', 'Subjetividad', 'palabras', 'Label_enc', 'nLabel'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>procesado</th>\n",
       "      <th>Label_enc</th>\n",
       "      <th>nLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>Aromantic</td>\n",
       "      <td>Who needs whips &amp;amp; chains when you have cak...</td>\n",
       "      <td>['needs', 'whips', 'amp', 'chains', 'cake']</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>KeedyKat</td>\n",
       "      <td>@SouthernBell07 u went to the ol' school for r...</td>\n",
       "      <td>['went', 'school', 'real', 'one', 'listening',...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>love2live10101</td>\n",
       "      <td>@Traphik Aww I'm sorry! I voted for u! @annspa...</td>\n",
       "      <td>['aww', 'sorry', 'voted', 'yesterday', 'droppe...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>liannebigworld</td>\n",
       "      <td>aargh I want to go home but it's raining and I...</td>\n",
       "      <td>['aargh', 'want', 'home', 'raining', 'bring', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>bahramd</td>\n",
       "      <td>I'm  so tired</td>\n",
       "      <td>['tired']</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>drea89</td>\n",
       "      <td>its super hot and i have a headache</td>\n",
       "      <td>['super', 'hot', 'headache']</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>mofabul0us</td>\n",
       "      <td>Wow I was winning beer pong but no longer</td>\n",
       "      <td>['wow', 'winning', 'beer', 'pong', 'long']</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>NKANGEL74</td>\n",
       "      <td>@troykids yay that's great</td>\n",
       "      <td>['yay', 'great']</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>paulinewood</td>\n",
       "      <td>My Mum is coming home from hospital today afte...</td>\n",
       "      <td>['mum', 'coming', 'home', 'hospital', 'today',...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>newyorklights</td>\n",
       "      <td>@ahluscu12 andreea.  you need an apple</td>\n",
       "      <td>['andreea', 'need', 'apple']</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                user                                               text  \\\n",
       "9254       Aromantic  Who needs whips &amp; chains when you have cak...   \n",
       "1561        KeedyKat  @SouthernBell07 u went to the ol' school for r...   \n",
       "1670  love2live10101  @Traphik Aww I'm sorry! I voted for u! @annspa...   \n",
       "6087  liannebigworld  aargh I want to go home but it's raining and I...   \n",
       "6669         bahramd                                     I'm  so tired    \n",
       "...              ...                                                ...   \n",
       "5734          drea89               its super hot and i have a headache    \n",
       "5191      mofabul0us         Wow I was winning beer pong but no longer    \n",
       "5390       NKANGEL74                        @troykids yay that's great    \n",
       "860      paulinewood  My Mum is coming home from hospital today afte...   \n",
       "7270   newyorklights            @ahluscu12 andreea.  you need an apple    \n",
       "\n",
       "                                              procesado  Label_enc  nLabel  \n",
       "9254        ['needs', 'whips', 'amp', 'chains', 'cake']          1       0  \n",
       "1561  ['went', 'school', 'real', 'one', 'listening',...          2       1  \n",
       "1670  ['aww', 'sorry', 'voted', 'yesterday', 'droppe...          0      -1  \n",
       "6087  ['aargh', 'want', 'home', 'raining', 'bring', ...          1       0  \n",
       "6669                                          ['tired']          0      -1  \n",
       "...                                                 ...        ...     ...  \n",
       "5734                       ['super', 'hot', 'headache']          2       1  \n",
       "5191         ['wow', 'winning', 'beer', 'pong', 'long']          2       1  \n",
       "5390                                   ['yay', 'great']          2       1  \n",
       "860   ['mum', 'coming', 'home', 'hospital', 'today',...          2       1  \n",
       "7270                       ['andreea', 'need', 'apple']          1       0  \n",
       "\n",
       "[8000 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop(columns = ['target', 'ids', 'date', 'flag','Polaridad', 'Subjetividad', 'palabras'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model: 0.588125 using {'bow__ngram_range': (1, 1), 'classifier__alpha': 0.01, 'tfidf__use_idf': False}\n",
      "\n",
      "\n",
      "Mean: 0.563125 Stdev:(0.034055) with: {'bow__ngram_range': (1, 1), 'classifier__alpha': 0.01, 'tfidf__use_idf': True}\n",
      "Mean: 0.588125 Stdev:(0.032410) with: {'bow__ngram_range': (1, 1), 'classifier__alpha': 0.01, 'tfidf__use_idf': False}\n",
      "Mean: 0.555000 Stdev:(0.036954) with: {'bow__ngram_range': (1, 1), 'classifier__alpha': 0.001, 'tfidf__use_idf': True}\n",
      "Mean: 0.575000 Stdev:(0.030362) with: {'bow__ngram_range': (1, 1), 'classifier__alpha': 0.001, 'tfidf__use_idf': False}\n",
      "Mean: 0.559375 Stdev:(0.031156) with: {'bow__ngram_range': (1, 2), 'classifier__alpha': 0.01, 'tfidf__use_idf': True}\n",
      "Mean: 0.585000 Stdev:(0.033680) with: {'bow__ngram_range': (1, 2), 'classifier__alpha': 0.01, 'tfidf__use_idf': False}\n",
      "Mean: 0.552500 Stdev:(0.038345) with: {'bow__ngram_range': (1, 2), 'classifier__alpha': 0.001, 'tfidf__use_idf': True}\n",
      "Mean: 0.570000 Stdev:(0.028614) with: {'bow__ngram_range': (1, 2), 'classifier__alpha': 0.001, 'tfidf__use_idf': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    3.7s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "X_train, X_test, y_train, y_test = train_test_split(train['text'][:2000], train['nLabel'][:2000], test_size=0.2)\n",
    "\n",
    "\n",
    "# create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(strip_accents='ascii',\n",
    "                            stop_words='english',\n",
    "                            lowercase=True)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "\n",
    "# this is where we define the values for GridSearchCV to iterate over\n",
    "parameters = {'bow__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'classifier__alpha': (1e-2, 1e-3),\n",
    "             }\n",
    "\n",
    "# do 10-fold cross validation for each of the 6 possible combinations of the above params\n",
    "grid = GridSearchCV(pipeline, cv=10, param_grid=parameters, verbose=1)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"\\nBest Model: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "print('\\n')\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"Mean: %f Stdev:(%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./input/twitter_sentiment.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(grid, \"./input/twitter_sentiment.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.65\n",
      "\n",
      "\n",
      "confusion matrix: \n",
      " [[ 43  19  26]\n",
      " [ 16  81  54]\n",
      " [ 11  14 136]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.61      0.49      0.54        88\n",
      "           0       0.71      0.54      0.61       151\n",
      "           1       0.63      0.84      0.72       161\n",
      "\n",
      "    accuracy                           0.65       400\n",
      "   macro avg       0.65      0.62      0.63       400\n",
      "weighted avg       0.66      0.65      0.64       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load from file and predict using the best configs found in the CV step\n",
    "model_NB = joblib.load(\"./input/twitter_sentiment.pkl\")\n",
    "\n",
    "# get predictions from best model above\n",
    "y_preds = model_NB.predict(X_test)\n",
    "\n",
    "print('accuracy score: ',accuracy_score(y_test, y_preds))\n",
    "print('\\n')\n",
    "print('confusion matrix: \\n',confusion_matrix(y_test,y_preds))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 12)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_preds = model_NB.predict(sent['text'])\n",
    "\n",
    "# append predictions to dataframe\n",
    "df_tweet_preds = sent.copy()\n",
    "df_tweet_preds['predictions'] = tweet_preds\n",
    "df_tweet_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 -- @dreambunny34d well how can we get your horny half full?  \n",
      "\n",
      "1 -- awww tireeeed,night ppl  \n",
      "\n",
      "1 -- Gonna Make A Video With Ash's New Song  \n",
      "\n",
      "1 -- @mileycyrus Please do another concert in Manchester in UK. Could not buy tickets and really me and my mates want to go your concert.  \n",
      "\n",
      "1 -- @MzEsha lol ok great cutie  \n",
      "\n",
      "1 -- maths exam didn't go well. i think i have a lot mistakes   A really busy day in school today. so i'll tweet u this eveneing. keep tweeting \n",
      "\n",
      "1 -- @dgritsko      travel safely! \n",
      "\n",
      "1 -- @RSD_Sufferer Thank you! lol  \n",
      "\n",
      "1 -- @NurseHunter you just need to register. Then email your blog to victoria.thompson@Emap.com - look forward to it  \n",
      "\n",
      "0 -- @wickedgoddess Happened to me too. Boo. No Blizzcon.  \n",
      "\n",
      "1 -- tmrw night The DOMINATION starts up a new week 6-7pm est.   \n",
      "\n",
      "0 -- shower, charity event, home.  textt itt. &lt;3 \n",
      "\n",
      "1 -- PRAISE THE LORD!!!!!  i love the lord! i really do  x \n",
      "\n",
      "1 -- These fire alarm and sprinkler people are the slowest people in the world. 2 hours later and still not done.  \n",
      "\n",
      "0 -- still learn twitter-ing.. gimana sih? nga ngerti  \n",
      "\n",
      "0 -- No way, just hit 2000 followers. Who woulda thunk it!  \n",
      "\n",
      "0 -- @lozzyjay  no,but i would like to follow you  \n",
      "\n",
      "1 -- @tphilipps Yeah, I got an email from the actual LaboratoryLogoContest@gmail, asking for my personal contact information. I am so excited!  \n",
      "\n",
      "1 -- @ashcashrain hey ashley, guess i didn't tell you yet but my padres r moving to st louis cuz my dad is starting a new job there, so i gtg2  \n",
      "\n",
      "0 -- @3thbi 3asa ma shar bro?  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# print text and sentiment\n",
    "\n",
    "index = random.sample(range(tweet_preds.shape[0]), 20)\n",
    "for text, sentiment in zip(df_tweet_preds.text[index],\n",
    "                           df_tweet_preds.predictions[index]):\n",
    "    print (sentiment, '--', text, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def polarity_scores_all(tweet):\n",
    "  '''\n",
    "  Takes string of text to:\n",
    "  1. Gets sentiment metrics\n",
    "  2. Returns negative, neutral, positive \n",
    "  and compound scores as lists.\n",
    "  '''\n",
    "  neg, neu, pos, compound = [], [], [], []\n",
    "  analyser = SentimentIntensityAnalyzer()\n",
    "  \n",
    "  for message in tweet:\n",
    "    dict_ = analyser.polarity_scores(message)\n",
    "    neg.append(dict_['neg'])\n",
    "    neu.append(dict_['neu'])\n",
    "    pos.append(dict_['pos'])\n",
    "    compound.append(dict_['compound'])\n",
    "  \n",
    "  return neg, neu, pos, compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-848d852c639e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolarity_scores_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocesado\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neg_scores'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neu_scores'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos_scores'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compound_scores'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-c5ef374b7eb2>\u001b[0m in \u001b[0;36mpolarity_scores_all\u001b[0;34m(tweet)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdict_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mneg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mneu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/vaderSentiment/vaderSentiment.py\u001b[0m in \u001b[0;36mpolarity_scores\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mtext_no_emoji\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mprev_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memojis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;31m# get the textual description\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "all_scores = polarity_scores_all(train.procesado.values)\n",
    "train['neg_scores'] = all_scores[0]\n",
    "train['neu_scores'] = all_scores[1]\n",
    "train['pos_scores'] = all_scores[2]\n",
    "train['compound_scores'] = all_scores[3]\n",
    "\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_family = {  \n",
    "    'NOUN' : ['NN','NNS','NNP'], # Removed 'NNPS'\n",
    "    'PRON' : ['PRP','PRP$','WP'],\n",
    "    'VERB' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "    'ADJ' :  ['JJ','JJR','JJS'],\n",
    "    'ADV' : ['RB','RBR','RBS','WRB']\n",
    "}\n",
    "\n",
    "def count_pos_tag(tweets):\n",
    "  '''\n",
    "  Takes string of text to:\n",
    "  1. Processes text and attaches POS tags\n",
    "  2. Input the dictionary of POS tags into a Counter.\n",
    "  2. Returns list of POS tags with occurrence number '''\n",
    "  total_count = []\n",
    "  for s in tweets:\n",
    "    partial_count = {}\n",
    "    s = s.split()\n",
    "    count_pos = Counter(dict(nltk.pos_tag(s)).values())\n",
    "    \n",
    "    for item, value in count_pos.items():\n",
    "      partial_count[item] = partial_count.get(item, 0) + 1\n",
    "            \n",
    "    total_count.append(partial_count)\n",
    "\n",
    "  return total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/fernandodelgadoteran/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.reindex of        WP  VBZ  NNS   NN  WRB  PRP  VBP   JJ  VBD   TO  ...  PDT  SYM   ,   $  \\\n",
       "0     1.0  1.0  1.0  1.0  1.0  1.0  1.0  NaN  NaN  NaN  ...  NaN  NaN NaN NaN   \n",
       "1     1.0  NaN  NaN  1.0  NaN  NaN  NaN  1.0  1.0  1.0  ...  NaN  NaN NaN NaN   \n",
       "2     NaN  NaN  NaN  1.0  NaN  1.0  1.0  1.0  1.0  NaN  ...  NaN  NaN NaN NaN   \n",
       "3     NaN  NaN  NaN  1.0  NaN  1.0  1.0  1.0  NaN  1.0  ...  NaN  NaN NaN NaN   \n",
       "4     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  1.0  NaN  ...  NaN  NaN NaN NaN   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ..  ..   \n",
       "7995  NaN  NaN  1.0  1.0  NaN  NaN  1.0  1.0  NaN  NaN  ...  NaN  NaN NaN NaN   \n",
       "7996  NaN  NaN  1.0  1.0  NaN  1.0  NaN  NaN  1.0  NaN  ...  NaN  NaN NaN NaN   \n",
       "7997  NaN  NaN  1.0  NaN  NaN  NaN  1.0  1.0  NaN  NaN  ...  NaN  NaN NaN NaN   \n",
       "7998  NaN  1.0  1.0  1.0  NaN  1.0  1.0  1.0  NaN  NaN  ...  NaN  NaN NaN NaN   \n",
       "7999  NaN  NaN  NaN  1.0  NaN  1.0  1.0  NaN  NaN  NaN  ...  NaN  NaN NaN NaN   \n",
       "\n",
       "      NNPS   )  POS  ''  RBS   (  \n",
       "0      NaN NaN  NaN NaN  NaN NaN  \n",
       "1      NaN NaN  NaN NaN  NaN NaN  \n",
       "2      NaN NaN  NaN NaN  NaN NaN  \n",
       "3      NaN NaN  NaN NaN  NaN NaN  \n",
       "4      NaN NaN  NaN NaN  NaN NaN  \n",
       "...    ...  ..  ...  ..  ...  ..  \n",
       "7995   NaN NaN  NaN NaN  NaN NaN  \n",
       "7996   NaN NaN  NaN NaN  NaN NaN  \n",
       "7997   NaN NaN  NaN NaN  NaN NaN  \n",
       "7998   NaN NaN  NaN NaN  NaN NaN  \n",
       "7999   NaN NaN  NaN NaN  NaN NaN  \n",
       "\n",
       "[8000 rows x 41 columns]>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve POS tags with occurrence \n",
    "total_count = count_pos_tag(train.text.values)\n",
    "# As dataframe \n",
    "pos_df = pd.DataFrame(total_count)\n",
    "# Remove unwanted characters\n",
    "# Inspection\n",
    "pos_df.reindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df['NOUN'] = pos_df[pos_family['NOUN']].sum(axis=1)\n",
    "pos_df['PRON'] = pos_df[pos_family['PRON']].sum(axis=1)\n",
    "pos_df['VERB'] = pos_df[pos_family['VERB']].sum(axis=1)\n",
    "pos_df['ADJ'] = pos_df[pos_family['ADJ']].sum(axis=1)\n",
    "pos_df['ADV'] = pos_df[pos_family['ADV']].sum(axis=1)\n",
    "\n",
    "pos_df = pos_df[['NOUN', 'PRON', 'VERB', 'ADJ', 'ADV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>procesado</th>\n",
       "      <th>Polaridad</th>\n",
       "      <th>Subjetividad</th>\n",
       "      <th>palabras</th>\n",
       "      <th>...</th>\n",
       "      <th>nLabel</th>\n",
       "      <th>neg_scores</th>\n",
       "      <th>neu_scores</th>\n",
       "      <th>pos_scores</th>\n",
       "      <th>compound_scores</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>PRON</th>\n",
       "      <th>VERB</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>1.971796e+09</td>\n",
       "      <td>Sat May 30 07:55:06 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>sazmataz_x</td>\n",
       "      <td>@katie_andhearts going in town later to get my...</td>\n",
       "      <td>['going', 'town', 'late', 'get', 'prom', 'shoe...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.65</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>1.978133e+09</td>\n",
       "      <td>Sat May 30 22:31:29 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Deasoy</td>\n",
       "      <td>happy day</td>\n",
       "      <td>['happy', 'day']</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>2.055155e+09</td>\n",
       "      <td>Sat Jun 06 08:48:06 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LianeGentrySkye</td>\n",
       "      <td>@jodywallace  Are you at the LF event?  I have...</td>\n",
       "      <td>['event', 'seen']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>2.054290e+09</td>\n",
       "      <td>Sat Jun 06 07:01:16 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>goodlaura</td>\n",
       "      <td>@TrippK I don't know how you manage with so ma...</td>\n",
       "      <td>['know', 'manage', 'many', 'blessings', 'see',...</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.50</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>1.677875e+09</td>\n",
       "      <td>Sat May 02 04:27:04 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Angfergie</td>\n",
       "      <td>@TheRealJordin Kat Von D's makeup rox too!</td>\n",
       "      <td>['kat', 'von', 'makeup', 'rox']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>1.961466e+09</td>\n",
       "      <td>Fri May 29 09:32:43 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Shashlye</td>\n",
       "      <td>..well OUR monkeys!!  Yay!!!</td>\n",
       "      <td>['well', 'monkeys', 'yay']</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>1.991740e+09</td>\n",
       "      <td>Mon Jun 01 07:34:48 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>officialpeta</td>\n",
       "      <td>@TradingGoddess Aww, she's beautiful!  My cats...</td>\n",
       "      <td>['aww', 'beautiful', 'cats', 'like', 'newspape...</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.95</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.7506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>2.065610e+09</td>\n",
       "      <td>Sun Jun 07 08:56:44 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>drfrankenpolish</td>\n",
       "      <td>@ARScherz Thanks, April</td>\n",
       "      <td>['thanks', 'april']</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9613 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target           ids                          date      flag  \\\n",
       "0            0  0.000000e+00                             0         0   \n",
       "1     Positiva  1.971796e+09  Sat May 30 07:55:06 PDT 2009  NO_QUERY   \n",
       "2     Positiva  1.978133e+09  Sat May 30 22:31:29 PDT 2009  NO_QUERY   \n",
       "3            0  0.000000e+00                             0         0   \n",
       "4      Neutral  2.055155e+09  Sat Jun 06 08:48:06 PDT 2009  NO_QUERY   \n",
       "...        ...           ...                           ...       ...   \n",
       "9994  Positiva  2.054290e+09  Sat Jun 06 07:01:16 PDT 2009  NO_QUERY   \n",
       "9995   Neutral  1.677875e+09  Sat May 02 04:27:04 PDT 2009  NO_QUERY   \n",
       "9996   Neutral  1.961466e+09  Fri May 29 09:32:43 PDT 2009  NO_QUERY   \n",
       "9997  Positiva  1.991740e+09  Mon Jun 01 07:34:48 PDT 2009  NO_QUERY   \n",
       "9999  Positiva  2.065610e+09  Sun Jun 07 08:56:44 PDT 2009  NO_QUERY   \n",
       "\n",
       "                 user                                               text  \\\n",
       "0                   0                                                  0   \n",
       "1          sazmataz_x  @katie_andhearts going in town later to get my...   \n",
       "2              Deasoy                                         happy day    \n",
       "3                   0                                                  0   \n",
       "4     LianeGentrySkye  @jodywallace  Are you at the LF event?  I have...   \n",
       "...               ...                                                ...   \n",
       "9994        goodlaura  @TrippK I don't know how you manage with so ma...   \n",
       "9995        Angfergie        @TheRealJordin Kat Von D's makeup rox too!    \n",
       "9996         Shashlye                       ..well OUR monkeys!!  Yay!!!   \n",
       "9997     officialpeta  @TradingGoddess Aww, she's beautiful!  My cats...   \n",
       "9999  drfrankenpolish                           @ARScherz Thanks, April    \n",
       "\n",
       "                                              procesado  Polaridad  \\\n",
       "0                                                     0      0.000   \n",
       "1     ['going', 'town', 'late', 'get', 'prom', 'shoe...      0.250   \n",
       "2                                      ['happy', 'day']      0.800   \n",
       "3                                                     0      0.000   \n",
       "4                                     ['event', 'seen']      0.000   \n",
       "...                                                 ...        ...   \n",
       "9994  ['know', 'manage', 'many', 'blessings', 'see',...      0.500   \n",
       "9995                    ['kat', 'von', 'makeup', 'rox']      0.000   \n",
       "9996                         ['well', 'monkeys', 'yay']      0.000   \n",
       "9997  ['aww', 'beautiful', 'cats', 'like', 'newspape...      0.575   \n",
       "9999                                ['thanks', 'april']      0.200   \n",
       "\n",
       "      Subjetividad  palabras  ...  nLabel  neg_scores  neu_scores  pos_scores  \\\n",
       "0             0.00       0.0  ...     0.0         0.0       0.000       0.000   \n",
       "1             0.65      14.0  ...     1.0         0.0       0.714       0.286   \n",
       "2             1.00       2.0  ...     1.0         0.0       0.213       0.787   \n",
       "3             0.00       0.0  ...     0.0         0.0       0.000       0.000   \n",
       "4             0.00      11.0  ...     0.0         0.0       1.000       0.000   \n",
       "...            ...       ...  ...     ...         ...         ...         ...   \n",
       "9994          0.50      16.0  ...     1.0         0.0       0.588       0.412   \n",
       "9995          0.00       7.0  ...     0.0         0.0       1.000       0.000   \n",
       "9996          0.00       4.0  ...     0.0         0.0       0.154       0.846   \n",
       "9997          0.95      15.0  ...     1.0         0.0       0.484       0.516   \n",
       "9999          0.20       3.0  ...     1.0         0.0       0.256       0.744   \n",
       "\n",
       "      compound_scores  NOUN  PRON  VERB  ADJ  ADV  \n",
       "0              0.0000   2.0   2.0   2.0  0.0  1.0  \n",
       "1              0.4215   1.0   1.0   3.0  1.0  0.0  \n",
       "2              0.5719   2.0   2.0   3.0  1.0  1.0  \n",
       "3              0.0000   1.0   1.0   3.0  1.0  0.0  \n",
       "4              0.0000   1.0   0.0   1.0  0.0  1.0  \n",
       "...               ...   ...   ...   ...  ...  ...  \n",
       "9994           0.5423   0.0   0.0   0.0  0.0  0.0  \n",
       "9995           0.0000   0.0   0.0   0.0  0.0  0.0  \n",
       "9996           0.6705   0.0   0.0   0.0  0.0  0.0  \n",
       "9997           0.7506   0.0   0.0   0.0  0.0  0.0  \n",
       "9999           0.4404   0.0   0.0   0.0  0.0  0.0  \n",
       "\n",
       "[9613 rows x 21 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([train, pos_df], axis = 1)\n",
    "train = train.fillna(value=0.0)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop_duplicates(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('./output/feat_train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>procesado</th>\n",
       "      <th>Polaridad</th>\n",
       "      <th>Subjetividad</th>\n",
       "      <th>palabras</th>\n",
       "      <th>...</th>\n",
       "      <th>nLabel</th>\n",
       "      <th>neg_scores</th>\n",
       "      <th>neu_scores</th>\n",
       "      <th>pos_scores</th>\n",
       "      <th>compound_scores</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>PRON</th>\n",
       "      <th>VERB</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>1.971796e+09</td>\n",
       "      <td>Sat May 30 07:55:06 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>sazmataz_x</td>\n",
       "      <td>@katie_andhearts going in town later to get my...</td>\n",
       "      <td>['going', 'town', 'late', 'get', 'prom', 'shoe...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.65</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>1.978133e+09</td>\n",
       "      <td>Sat May 30 22:31:29 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Deasoy</td>\n",
       "      <td>happy day</td>\n",
       "      <td>['happy', 'day']</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>2.055155e+09</td>\n",
       "      <td>Sat Jun 06 08:48:06 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LianeGentrySkye</td>\n",
       "      <td>@jodywallace  Are you at the LF event?  I have...</td>\n",
       "      <td>['event', 'seen']</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>2.066500e+09</td>\n",
       "      <td>Sun Jun 07 10:38:18 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>darkrumblog</td>\n",
       "      <td>@Fleshworks Excellent, very good indeed!  Am p...</td>\n",
       "      <td>['excellent', 'good', 'indeed', 'posting']</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.80</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target           ids                          date      flag  \\\n",
       "0         0  0.000000e+00                             0         0   \n",
       "1  Positiva  1.971796e+09  Sat May 30 07:55:06 PDT 2009  NO_QUERY   \n",
       "2  Positiva  1.978133e+09  Sat May 30 22:31:29 PDT 2009  NO_QUERY   \n",
       "4   Neutral  2.055155e+09  Sat Jun 06 08:48:06 PDT 2009  NO_QUERY   \n",
       "5  Positiva  2.066500e+09  Sun Jun 07 10:38:18 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \\\n",
       "0                0                                                  0   \n",
       "1       sazmataz_x  @katie_andhearts going in town later to get my...   \n",
       "2           Deasoy                                         happy day    \n",
       "4  LianeGentrySkye  @jodywallace  Are you at the LF event?  I have...   \n",
       "5      darkrumblog  @Fleshworks Excellent, very good indeed!  Am p...   \n",
       "\n",
       "                                           procesado  Polaridad  Subjetividad  \\\n",
       "0                                                  0       0.00          0.00   \n",
       "1  ['going', 'town', 'late', 'get', 'prom', 'shoe...       0.25          0.65   \n",
       "2                                   ['happy', 'day']       0.80          1.00   \n",
       "4                                  ['event', 'seen']       0.00          0.00   \n",
       "5         ['excellent', 'good', 'indeed', 'posting']       0.85          0.80   \n",
       "\n",
       "   palabras  ...  nLabel  neg_scores  neu_scores  pos_scores  compound_scores  \\\n",
       "0       0.0  ...     0.0         0.0       0.000       0.000           0.0000   \n",
       "1      14.0  ...     1.0         0.0       0.714       0.286           0.4215   \n",
       "2       2.0  ...     1.0         0.0       0.213       0.787           0.5719   \n",
       "4      11.0  ...     0.0         0.0       1.000       0.000           0.0000   \n",
       "5       9.0  ...     1.0         0.0       0.233       0.767           0.7650   \n",
       "\n",
       "   NOUN  PRON  VERB  ADJ  ADV  \n",
       "0   2.0   2.0   2.0  0.0  1.0  \n",
       "1   1.0   1.0   3.0  1.0  0.0  \n",
       "2   2.0   2.0   3.0  1.0  1.0  \n",
       "4   1.0   0.0   1.0  0.0  1.0  \n",
       "5   2.0   0.0   0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().values.any()\n",
    "train_prep=train.copy()\n",
    "train_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7998, 5), (7998, 1))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting Features\n",
    "features = ['text', 'neu_scores', 'neg_scores', 'compound_scores', 'pos_scores']\n",
    "label = ['nLabel']\n",
    "# Saving features and label data in X and y for train-test split\n",
    "X = train_prep[[col for col in train_prep.columns if col in features]]\n",
    "y = train_prep[label]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes are (5598, 5) and (2400, 5)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "print(\"Shapes are {} and {}\".format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    0.419078\n",
       " 0.0    0.371383\n",
       "-1.0    0.209539\n",
       "dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train.values.ravel()).value_counts(normalize=True)\n",
    "pd.Series(y_train.values.ravel()).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#el dataset tiene una probabilidad de acertar del 42% si es positivo,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline to convert tweets to a matrix of TF-IDF features.\n",
    "tfidf = Pipeline([\n",
    "                ('selector', TextSelector(key='text')),\n",
    "                ('tfidf', TfidfVectorizer())\n",
    "            ])\n",
    "\n",
    "# Pipeline to convert tweets to a matrix of token counts\n",
    "countvect = Pipeline([\n",
    "                ('selector', TextSelector(key='text')),\n",
    "                ('countvect', CountVectorizer())\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying tfidf anf countvec to features\n",
    "\n",
    "neu_scores =  Pipeline([\n",
    "                ('selector', NumberSelector(key='neu_scores')),\n",
    "                ('minmax', MinMaxScaler())\n",
    "            ])\n",
    "neg_scores =  Pipeline([\n",
    "                ('selector', NumberSelector(key='neg_scores')),\n",
    "                ('minmax', MinMaxScaler())\n",
    "            ])\n",
    "pos_scores =  Pipeline([\n",
    "                ('selector', NumberSelector(key='pos_scores')),\n",
    "                ('minmax', MinMaxScaler())\n",
    "            ])\n",
    "\n",
    "compound_scores =  Pipeline([\n",
    "                ('selector', NumberSelector(key='compound_scores')),\n",
    "                ('minmax', MinMaxScaler())\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining different sets of text processors\n",
    "def features_union(textProcessor):\n",
    "    return FeatureUnion([('text', textProcessor),\n",
    "                      ('neu_scores', neu_scores),\n",
    "                      ('neg_scores', neg_scores),\n",
    "                      ('pos_scores', pos_scores),\n",
    "                      ('compound_scores', compound_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5598, 5), (2400, 5))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder().fit(y_train.values.ravel())\n",
    "\n",
    "y_train = le.transform(y_train.values.ravel())\n",
    "y_test = le.transform(y_test.values.ravel())\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6991666666666667"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate classifier\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# combine features\n",
    "features_count = features_union(countvect)\n",
    "\n",
    "# define pipeline object \n",
    "nb_pipeline = Pipeline([('features', features_count),\n",
    "                       ('nb', clf)])\n",
    "\n",
    "# Fit classifier\n",
    "nb_pipeline.fit(X_train.astype(str), y_train)\n",
    "\n",
    "# score\n",
    "nb_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8541666666666666"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate classifier\n",
    "svm = LinearSVC()\n",
    "\n",
    "#  combine features\n",
    "features_tfidf = features_union(tfidf)\n",
    "\n",
    "# define pipeline object\n",
    "svm_pipeline = Pipeline([('features', features_tfidf),\n",
    "                       ('svm', svm)])\n",
    "\n",
    "# Fit classifier\n",
    "svm_pipeline.fit(X_train.astype(str), y_train)\n",
    "\n",
    "# score\n",
    "svm_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run: 3.2 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.68625"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes Classifier\n",
    "\n",
    "# combine features\n",
    "features_tfidf = features_union(tfidf)\n",
    "\n",
    "# instantiate pipeline object\n",
    "nb_pipeline = Pipeline([('feats', features_tfidf),  ('clf', MultinomialNB())])\n",
    "\n",
    "# parameter grid (3x3x2x2x3x3x2) combinations\n",
    "parameters = {\n",
    "    'feats__text__tfidf__max_df': (0.5, 0.75, 1.0),\n",
    "    'feats__text__tfidf__ngram_range': ((1, 1), (1, 2), (2, 2)), \n",
    "    'feats__text__tfidf__use_idf': (False, True),\n",
    "    'feats__text__tfidf__binary':(False, True),\n",
    "    'feats__text__tfidf__binary':('l1', 'l2', None),\n",
    "    'clf__alpha': (1.0, 5.0, 10.0),\n",
    "    'clf__fit_prior': (True, False),     \n",
    "}\n",
    "\n",
    "# instantiate GridSearchCV object with pipeline and parameters with 3-folds cross-validation\n",
    "nb_grid = GridSearchCV(nb_pipeline, parameters, cv=3) # this takes a while :/\n",
    "\n",
    "# start time \n",
    "nb_start = time.time()\n",
    "\n",
    "# Fit \n",
    "nb_grid.fit(X_train.astype(str), y_train)\n",
    "\n",
    "# end time \n",
    "svm_end = time.time()\n",
    "print(f\"Time taken to run: {round((svm_end - nb_start)/60,1)} minutes\")\n",
    "\n",
    "# Check score\n",
    "nb_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'feats__text__tfidf__binary': 'l1', 'feats__text__tfidf__max_df': 0.5, 'feats__text__tfidf__ngram_range': (1, 1), 'feats__text__tfidf__use_idf': True}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__alpha</th>\n",
       "      <th>param_clf__fit_prior</th>\n",
       "      <th>param_feats__text__tfidf__binary</th>\n",
       "      <th>param_feats__text__tfidf__max_df</th>\n",
       "      <th>param_feats__text__tfidf__ngram_range</th>\n",
       "      <th>param_feats__text__tfidf__use_idf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088420</td>\n",
       "      <td>0.006950</td>\n",
       "      <td>0.034165</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__alpha': 1.0, 'clf__fit_prior': True, 'f...</td>\n",
       "      <td>0.595391</td>\n",
       "      <td>0.608253</td>\n",
       "      <td>0.609861</td>\n",
       "      <td>0.604502</td>\n",
       "      <td>0.006475</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.086189</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.038717</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__alpha': 1.0, 'clf__fit_prior': True, 'f...</td>\n",
       "      <td>0.610397</td>\n",
       "      <td>0.628081</td>\n",
       "      <td>0.627010</td>\n",
       "      <td>0.621829</td>\n",
       "      <td>0.008096</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.200385</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.058952</td>\n",
       "      <td>0.004798</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__alpha': 1.0, 'clf__fit_prior': True, 'f...</td>\n",
       "      <td>0.536977</td>\n",
       "      <td>0.549303</td>\n",
       "      <td>0.536442</td>\n",
       "      <td>0.540907</td>\n",
       "      <td>0.005941</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.088420      0.006950         0.034165        0.001112   \n",
       "1       0.086189      0.002420         0.038717        0.003986   \n",
       "2       0.200385      0.001798         0.058952        0.004798   \n",
       "\n",
       "  param_clf__alpha param_clf__fit_prior param_feats__text__tfidf__binary  \\\n",
       "0                1                 True                               l1   \n",
       "1                1                 True                               l1   \n",
       "2                1                 True                               l1   \n",
       "\n",
       "  param_feats__text__tfidf__max_df param_feats__text__tfidf__ngram_range  \\\n",
       "0                              0.5                                (1, 1)   \n",
       "1                              0.5                                (1, 1)   \n",
       "2                              0.5                                (1, 2)   \n",
       "\n",
       "  param_feats__text__tfidf__use_idf  \\\n",
       "0                             False   \n",
       "1                              True   \n",
       "2                             False   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'clf__alpha': 1.0, 'clf__fit_prior': True, 'f...           0.595391   \n",
       "1  {'clf__alpha': 1.0, 'clf__fit_prior': True, 'f...           0.610397   \n",
       "2  {'clf__alpha': 1.0, 'clf__fit_prior': True, 'f...           0.536977   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.608253           0.609861         0.604502        0.006475   \n",
       "1           0.628081           0.627010         0.621829        0.008096   \n",
       "2           0.549303           0.536442         0.540907        0.005941   \n",
       "\n",
       "   rank_test_score  \n",
       "0               91  \n",
       "1               73  \n",
       "2              181  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Best params: {}'.format(nb_grid.best_params_))\n",
    "nb_cv_results = pd.DataFrame(nb_grid.cv_results_)\n",
    "nb_cv_results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run: 11.0 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8758333333333334"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Classifier\n",
    "\n",
    "# combine features\n",
    "features_count = features_union(tfidf)\n",
    "\n",
    "# instantiate pipeline\n",
    "svm_count_pipeline = Pipeline([('feats', features_count),  ('clf', LinearSVC(max_iter=10000))])\n",
    "\n",
    "# parameter grid (3x3x2x3x7x2) combinations\n",
    "parameters = {\n",
    "    'feats__text__tfidf__max_df': (0.5, 0.75, 1.0),\n",
    "    'feats__text__tfidf__ngram_range': ((1, 1), (1, 2), (2, 2)), \n",
    "    'feats__text__tfidf__use_idf': (False, True),\n",
    "    'clf__loss': ('hinge', 'squared_hinge'),\n",
    "    'clf__C': (0.1, 0.5, 0.6, 1, 4, 5, 10, 100),\n",
    "    'clf__class_weight': (None, 'balanced')                                    \n",
    "}\n",
    "\n",
    "# instantiate GridSearchCV object with pipeline and parameters with 3-folds cross-validation\n",
    "svm_grid = GridSearchCV(svm_count_pipeline, parameters, cv=3)\n",
    "\n",
    "# start time \n",
    "svm_start = time.time()\n",
    "\n",
    "# fit\n",
    "svm_grid.fit(X_train.astype(str), y_train)\n",
    "\n",
    "# end time \n",
    "svm_end = time.time()\n",
    "print(f\"Time taken to run: {round((svm_end - svm_start)/60,1)} minutes\")\n",
    "\n",
    "# score\n",
    "svm_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'grid_scores_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-4b90f704e0cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvm_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'grid_scores_'"
     ]
    }
   ],
   "source": [
    "#svm_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__C': 4, 'clf__class_weight': None, 'clf__loss': 'hinge', 'feats__text__tfidf__max_df': 0.5, 'feats__text__tfidf__ngram_range': (1, 1), 'feats__text__tfidf__use_idf': False}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_clf__class_weight</th>\n",
       "      <th>param_clf__loss</th>\n",
       "      <th>param_feats__text__tfidf__max_df</th>\n",
       "      <th>param_feats__text__tfidf__ngram_range</th>\n",
       "      <th>param_feats__text__tfidf__use_idf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.099182</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>0.035325</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': None, 'cl...</td>\n",
       "      <td>0.730975</td>\n",
       "      <td>0.698285</td>\n",
       "      <td>0.716506</td>\n",
       "      <td>0.715255</td>\n",
       "      <td>0.013375</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.107523</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>0.037750</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': None, 'cl...</td>\n",
       "      <td>0.727760</td>\n",
       "      <td>0.696141</td>\n",
       "      <td>0.713290</td>\n",
       "      <td>0.712397</td>\n",
       "      <td>0.012924</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.214999</td>\n",
       "      <td>0.011389</td>\n",
       "      <td>0.057595</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': None, 'cl...</td>\n",
       "      <td>0.727760</td>\n",
       "      <td>0.692390</td>\n",
       "      <td>0.713290</td>\n",
       "      <td>0.711147</td>\n",
       "      <td>0.014519</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_clf__C  \\\n",
       "0       0.099182      0.007122         0.035325        0.001046          0.1   \n",
       "1       0.107523      0.008120         0.037750        0.000495          0.1   \n",
       "2       0.214999      0.011389         0.057595        0.002108          0.1   \n",
       "\n",
       "  param_clf__class_weight param_clf__loss param_feats__text__tfidf__max_df  \\\n",
       "0                    None           hinge                              0.5   \n",
       "1                    None           hinge                              0.5   \n",
       "2                    None           hinge                              0.5   \n",
       "\n",
       "  param_feats__text__tfidf__ngram_range param_feats__text__tfidf__use_idf  \\\n",
       "0                                (1, 1)                             False   \n",
       "1                                (1, 1)                              True   \n",
       "2                                (1, 2)                             False   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'clf__C': 0.1, 'clf__class_weight': None, 'cl...           0.730975   \n",
       "1  {'clf__C': 0.1, 'clf__class_weight': None, 'cl...           0.727760   \n",
       "2  {'clf__C': 0.1, 'clf__class_weight': None, 'cl...           0.727760   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.698285           0.716506         0.715255        0.013375   \n",
       "1           0.696141           0.713290         0.712397        0.012924   \n",
       "2           0.692390           0.713290         0.711147        0.014519   \n",
       "\n",
       "   rank_test_score  \n",
       "0              364  \n",
       "1              397  \n",
       "2              427  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Best params: {}'.format(svm_grid.best_params_))\n",
    "svm_cv_results = pd.DataFrame(svm_grid.cv_results_)\n",
    "svm_cv_results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier saved\n",
      "SVM Classifier saved\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(nb_grid, \"./output/twitter_sentiment_naivebayes.pkl\")\n",
    "print('Naive Bayes Classifier saved')\n",
    "joblib.dump(svm_grid, \"./output/twitter_sentiment_svm.pkl\")\n",
    "print('SVM Classifier saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and save predictions from best models above\n",
    "\n",
    "# Naive Bayes\n",
    "y_preds_nb = nb_grid.predict(X_test)\n",
    "# Save predictions for evaluation as numpy arrays\n",
    "np.save('./output/y_predsNB.npy', y_preds_nb)\n",
    "\n",
    "# Support Vector Machine\n",
    "y_preds_svm = svm_grid.predict(X_test)\n",
    "# Save predictions for evaluation as numpy arrays\n",
    "np.save('./output/y_predsSVM.npy', y_preds_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar dataset para evaluacion\n",
    "np.save('./output/y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter indicating the number of words\n",
    "nb_words = 10000  \n",
    "\n",
    "## create the tokenizer (tweets have been preprocessed so no need for filters)\n",
    "tk = Tokenizer(num_words=nb_words)\n",
    "\n",
    "# fit the tokenizer on tweets\n",
    "tk.fit_on_texts(train_prep.text.astype(str))\n",
    "\n",
    "# integer encode tweets\n",
    "tweets_seq = tk.texts_to_sequences(train_prep.text.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prep['palabras']=sent['palabras']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7998.000000\n",
       "mean       13.196049\n",
       "std         6.939516\n",
       "min         1.000000\n",
       "25%         7.000000\n",
       "50%        12.000000\n",
       "75%        19.000000\n",
       "max        34.000000\n",
       "Name: palabras, dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prep['palabras'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cada batch debe tener secuencias de la misma longitud, esto se logra con el metodo pad_sequences, especificando la longitud sera acolchada con ceros o se truncara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum length since maximum tweet word count is 28.\n",
    "max_len = 28\n",
    "\n",
    "# Convert sequences into 2-D Numpy arrays\n",
    "features = pad_sequences(tweets_seq, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test statements \n",
    "assert len(features)==len(tweets_seq), \"The features should have as many rows as tweets.\"\n",
    "assert len(features[0])==max_len, \"Each feature row should contain the mex length of values.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of 0       0.0\n",
       "1       1.0\n",
       "2       1.0\n",
       "4       0.0\n",
       "5       1.0\n",
       "       ... \n",
       "9994    1.0\n",
       "9995    0.0\n",
       "9996    0.0\n",
       "9997    1.0\n",
       "9999    1.0\n",
       "Name: nLabel, Length: 7998, dtype: category\n",
       "Categories (3, float64): [-1.0, 0.0, 1.0]>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to hot-encode\n",
    "train_prep[\"nLabel\"] = train_prep[\"nLabel\"].astype(\"category\")\n",
    "train_prep.nLabel.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set X: \t\t(6398, 28) \n",
      "Train set Y: \t\t(6398, 3) \n",
      "Test set X: \t\t(1600, 28) \n",
      "Test set Y: \t\t(1600, 3)\n"
     ]
    }
   ],
   "source": [
    "## split data into training and test data (features and labels, x and y)\n",
    "# data needs to be as array\n",
    "labels = pd.get_dummies(train_prep['nLabel']).values\n",
    "#labels = np.asarray(train_prep.label.values)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size = 0.2, random_state = 42)\n",
    "\n",
    "## print out the shapes of the resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set X: \\t\\t{}\".format(X_train.shape),\n",
    "      \"\\nTrain set Y: \\t\\t{}\".format(Y_train.shape),\n",
    "      \"\\nTest set X: \\t\\t{}\".format(X_test.shape),\n",
    "      \"\\nTest set Y: \\t\\t{}\".format(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Network with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, training on CPU.\n"
     ]
    }
   ],
   "source": [
    "# First checking if GPU is available\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Model: \"modeloKeras\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 28, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 200)               263200    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 603       \n",
      "=================================================================\n",
      "Total params: 1,543,803\n",
      "Trainable params: 1,543,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "\n",
    "#--- Parameters----#\n",
    "\n",
    "# encodes input sequence dense vectors \n",
    "embed_dim = 128\n",
    "\n",
    "# transforms the vector sequence into a single vector\n",
    "lstm_out = 200\n",
    "\n",
    "# batch size of 32 is a good starting point\n",
    "batch_size = 32\n",
    "\n",
    "# epochs\n",
    "epochs = 10\n",
    "\n",
    "#------# Build the LSTM model #-----------------#\n",
    "\n",
    "print('Building model...') \n",
    "\n",
    "# Initialising the RNN\n",
    "model = Sequential()\n",
    "\n",
    "#adding an input layer and the first hidden layer\n",
    "model.add(Embedding(10000, embed_dim, \n",
    "                    input_length = features.shape[1], \n",
    "                   )) \n",
    "model.add(Dropout(0.2))\n",
    "# Adding the second hidden layer\n",
    "model.add(LSTM(lstm_out))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile( optimizer='adam', # optimazer\n",
    "              loss = 'categorical_crossentropy', # loss function\n",
    "              metrics = ['accuracy']) # list of metrics\n",
    "\n",
    "model._name = 'modeloKeras'\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 0.9267 - accuracy: 0.5639 - val_loss: 0.7803 - val_accuracy: 0.6719\n",
      "Epoch 2/10\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 0.4185 - accuracy: 0.8467 - val_loss: 0.4819 - val_accuracy: 0.8305\n",
      "Epoch 3/10\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 0.1451 - accuracy: 0.9620 - val_loss: 0.5319 - val_accuracy: 0.8097\n",
      "Epoch 4/10\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 0.0633 - accuracy: 0.9865 - val_loss: 0.6197 - val_accuracy: 0.8272\n",
      "Epoch 5/10\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 0.0374 - accuracy: 0.9900 - val_loss: 0.6072 - val_accuracy: 0.8234\n",
      "Epoch 6/10\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 0.0240 - accuracy: 0.9942 - val_loss: 0.6999 - val_accuracy: 0.8106\n",
      "Epoch 7/10\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 0.0335 - accuracy: 0.9911 - val_loss: 0.8877 - val_accuracy: 0.8101\n",
      "Epoch 8/10\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 0.0190 - accuracy: 0.9951 - val_loss: 0.7386 - val_accuracy: 0.8234\n",
      "Epoch 9/10\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 0.9493 - val_accuracy: 0.8291\n",
      "Epoch 10/10\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.9765 - val_accuracy: 0.8201\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit(X_train, Y_train, \n",
    "                    validation_split=0.33, \n",
    "                    batch_size = batch_size, \n",
    "                    epochs = epochs, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric(model, history, metric_name):\n",
    "    '''\n",
    "    Function to evaluate a trained model on a chosen metric. \n",
    "    Training and validation metric are plotted in a\n",
    "    line chart for each epoch.\n",
    "    \n",
    "    Parameters:\n",
    "        history : model training history\n",
    "        metric_name : loss or accuracy\n",
    "    Output:\n",
    "        line chart with epochs of x-axis and metric on\n",
    "        y-axis\n",
    "    '''\n",
    "    metric = history.history[metric_name]\n",
    "    val_metric = history.history['val_' + metric_name]\n",
    "\n",
    "    e = range(1, epochs + 1)\n",
    "\n",
    "    plt.plot(e, metric, 'ro', label='Train ' + metric_name)\n",
    "    plt.plot(e, val_metric, 'r', label='Validation ' + metric_name)\n",
    "    plt.xlabel('Epoch number')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.title('Comparing training and validation ' + metric_name + ' for ' + model.name)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def optimal_epoch(model_hist):\n",
    "    '''\n",
    "    Function to return the epoch number where the validation loss is\n",
    "    at its minimum\n",
    "    \n",
    "    Parameters:\n",
    "        model_hist : training history of model\n",
    "    Output:\n",
    "        epoch number with minimum validation loss\n",
    "    '''\n",
    "    min_epoch = np.argmin(model_hist.history['val_loss']) + 1\n",
    "    print(\"Minimum validation loss reached in epoch {}\".format(min_epoch))\n",
    "    return min_epoch\n",
    "\n",
    "def test_model(model, X_train, y_train, X_test, y_test, epoch_stop):\n",
    "    '''\n",
    "    Function to test the model on new data after training it\n",
    "    on the full training data with the optimal number of epochs.\n",
    "    \n",
    "    Parameters:\n",
    "        model : trained model\n",
    "        X_train : training features\n",
    "        y_train : training target\n",
    "        X_test : test features\n",
    "        y_test : test target\n",
    "        epochs : optimal number of epochs\n",
    "    Output:\n",
    "        test accuracy and test loss\n",
    "    '''\n",
    "    model.fit(X_train\n",
    "              , y_train\n",
    "              , epochs=epoch_stop\n",
    "              , batch_size=epochs\n",
    "              , verbose=0)\n",
    "    results = model.evaluate(X_test, y_test)\n",
    "    print()\n",
    "    print('Test accuracy: {0:.2f}%'.format(results[1]*100))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum validation loss reached in epoch 2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "eval_metric(model, history, 'loss')\n",
    "print(optimal_epoch(history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 28, 128)           1920000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200)               263200    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 603       \n",
      "=================================================================\n",
      "Total params: 2,183,803\n",
      "Trainable params: 2,183,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Applying regularisation\n",
    "\n",
    "print('Building model...') \n",
    "\n",
    "reg_model = Sequential()\n",
    "reg_model.add(Embedding(15000, embed_dim, input_length = features.shape[1]))\n",
    "model.add(Dropout(0.2))\n",
    "reg_model.add(LSTM(lstm_out))\n",
    "reg_model.add(Dense(3, kernel_regularizer=regularizers.l2(0.001), activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "reg_model.compile( optimizer='adam', # optimazer\n",
    "              loss = 'categorical_crossentropy', # loss function\n",
    "              metrics = ['accuracy']) # list of metrics\n",
    "\n",
    "model._name = 'modeloKerasreg'\n",
    "print(reg_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "429/429 [==============================] - 11s 25ms/step - loss: 0.8134 - accuracy: 0.6377 - val_loss: 0.5604 - val_accuracy: 0.7945\n",
      "Epoch 2/10\n",
      "429/429 [==============================] - 11s 27ms/step - loss: 0.2861 - accuracy: 0.9092 - val_loss: 0.4675 - val_accuracy: 0.8362\n",
      "Epoch 3/10\n",
      "429/429 [==============================] - 11s 25ms/step - loss: 0.1170 - accuracy: 0.9692 - val_loss: 0.4749 - val_accuracy: 0.8494\n",
      "Epoch 4/10\n",
      "429/429 [==============================] - 11s 26ms/step - loss: 0.0740 - accuracy: 0.9813 - val_loss: 0.6051 - val_accuracy: 0.8452\n",
      "Epoch 5/10\n",
      "429/429 [==============================] - 14s 32ms/step - loss: 0.0506 - accuracy: 0.9904 - val_loss: 0.6005 - val_accuracy: 0.8485\n",
      "Epoch 6/10\n",
      "429/429 [==============================] - 14s 33ms/step - loss: 0.0414 - accuracy: 0.9897 - val_loss: 0.6768 - val_accuracy: 0.8177\n",
      "Epoch 7/10\n",
      "429/429 [==============================] - 17s 39ms/step - loss: 0.0314 - accuracy: 0.9939 - val_loss: 0.6804 - val_accuracy: 0.8310\n",
      "Epoch 8/10\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.0333 - accuracy: 0.9935 - val_loss: 0.6116 - val_accuracy: 0.8438\n",
      "Epoch 9/10\n",
      "429/429 [==============================] - 14s 33ms/step - loss: 0.0368 - accuracy: 0.9918 - val_loss: 0.6315 - val_accuracy: 0.8499\n",
      "Epoch 10/10\n",
      "429/429 [==============================] - 12s 29ms/step - loss: 0.0186 - accuracy: 0.9970 - val_loss: 0.7762 - val_accuracy: 0.8201\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "reg_history = reg_model.fit(X_train, Y_train, \n",
    "                    validation_split=0.33, \n",
    "                    batch_size = epochs, \n",
    "                    epochs = epochs, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum validation loss reached in epoch 2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "eval_metric(reg_model, reg_history, 'loss')\n",
    "print(optimal_epoch(reg_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 8ms/step - loss: 0.3926 - accuracy: 0.8813\n",
      "\n",
      "Test accuracy: 88.13%\n"
     ]
    }
   ],
   "source": [
    "# Optimal epochs\n",
    "base_min = 1 # first model\n",
    "reg_min = 2 # model with regularisation\n",
    "\n",
    "# Training on the full train data and evaluation on test data on first model\n",
    "base_results = test_model(model, X_train, Y_train, X_test, Y_test, base_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 10ms/step - loss: 0.5195 - accuracy: 0.8531\n",
      "\n",
      "Test accuracy: 85.31%\n"
     ]
    }
   ],
   "source": [
    "# Training on second model with regularisation and evaluation on data on second model\n",
    "reg_results = test_model(reg_model, X_train, Y_train, X_test, Y_test, reg_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LSTM model to models folder\n",
      "Saved LSTM model to models folder\n"
     ]
    }
   ],
   "source": [
    "#save first model and architecture\n",
    "model.save('./modelos/LSTM_model.h5')\n",
    "print('Saved LSTM model to models folder')\n",
    "\n",
    "# save second model and architecture\n",
    "reg_model.save('./modelos/LSTM_regmodel.h5')\n",
    "print('Saved LSTM model to models folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving predictions\n",
    "X_train, X_test, Y_train, Y_test\n",
    "\n",
    "#-- LSTM model ----#\n",
    "y_preds_LSTM = model.predict(X_test)\n",
    "\n",
    "# Save predictions for evaluation as numpy arrays\n",
    "np.save('./predictions/y_predsLSTM.npy', y_preds_LSTM)\n",
    "\n",
    "#-- LSTM with regularisation model ----#\n",
    "y_preds_LSTMreg = reg_model.predict(X_test)\n",
    "\n",
    "# Save predictions for evaluation as numpy arrays\n",
    "np.save('./predictions/y_predsLSTMreg.npy', y_preds_LSTMreg)\n",
    "\n",
    "# Save test data\n",
    "np.save('./output/y_testLSTM.npy', Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
