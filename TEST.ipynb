{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "from collections import Counter\n",
    "import re\n",
    "import string \n",
    "\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.porter import * \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= pd.read_csv(\"./output/final_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target',\n",
       " 'ids',\n",
       " 'date',\n",
       " 'flag',\n",
       " 'user',\n",
       " 'text',\n",
       " 'procesado',\n",
       " 'Polaridad',\n",
       " 'Subjetividad',\n",
       " 'palabras']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet= test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/fernandodelgadoteran/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTweet(tweet):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Removes links, special characters and other bulk cleaning\n",
    "    2. Returns a list of the tidy text\n",
    "    \"\"\"\n",
    "    # Remove HTML special entities (e.g. &amp;)\n",
    "    tweet = re.sub(r'\\&\\w*;', '', tweet)\n",
    "    #Convert @username to AT_USER\n",
    "    tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    # Remove tickers\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # To lowercase\n",
    "    tweet = tweet.lower()\n",
    "    # Remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*\\/\\w*', '', tweet)\n",
    "    # Remove hashtags\n",
    "    tweet = re.sub(r'#\\w*', '', tweet)\n",
    "    # Remove words with 2 or fewer letters\n",
    "    tweet = re.sub(r'\\b\\w{1,2}\\b', '', tweet)\n",
    "    # Remove whitespace (including new line characters)\n",
    "    tweet = re.sub(r'\\s\\s+', ' ', tweet)\n",
    "    # Remove single space remaining at the front of the tweet.\n",
    "    tweet = tweet.lstrip(' ') \n",
    "    # Remove characters beyond Basic Multilingual Plane (BMP) of Unicode:\n",
    "    tweet = ''.join(c for c in tweet if c <= '\\uFFFF') \n",
    "    return tweet\n",
    "# tokenize helper function\n",
    "def text_process(tweet):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in list(tweet) if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.lower().split() if word.lower() not in stopwords.words('english')]\n",
    "\n",
    "# Lexicon normalisation with Stemming \n",
    "def stemming(tokens):\n",
    "  \"\"\"\n",
    "  Takes in a string of text, then performs the following:\n",
    "  1. Replace words for its root based on orter Stemmer rule.\n",
    "  2. Returns normalised text\n",
    "   \"\"\"\n",
    "  stemmer = PorterStemmer()\n",
    "  x = [stemmer.stem(w) for w in tokens]\n",
    "   \n",
    "  return ' '.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    fell asleep around last night woke around . ca...\n",
      "1    going town later get prom shoes and other thin...\n",
      "2                                           happy day \n",
      "3                            tummy hurts stupid stress\n",
      "4                 are you the event? haven' seen you. \n",
      "Name: mensajeprocesado, dtype: object\n",
      "0     MissScion Fell asleep around  p last night wo...\n",
      "1     katie andhearts going in town later to get my...\n",
      "2                                           happy day \n",
      "3                           Tummy Hurts  Stupid Stress\n",
      "4     jodywallace  Are you at the LF event   I have...\n",
      "Name: mensajeprocesado, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "df_tweet['mensajeprocesado'] = df_tweet['text'].apply(processTweet)\n",
    "print(df_tweet.mensajeprocesado.head())\n",
    "# Double check\n",
    "df_tweet['mensajeprocesado'] = df_tweet['text'].str.replace(\"[^a-zA-Z#]\", \" \") \n",
    "print(df_tweet.mensajeprocesado.head())\n",
    "# tokenize tidy_tweet column and create a column for tokens\n",
    "test['tokens'] = df_tweet['procesado'].copy() # tokenize\n",
    "\n",
    "# Normalisation\n",
    "stemmer = PorterStemmer() \n",
    "normalized_tweet = df_tweet['mensajeprocesado'].apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n",
    "\n",
    "for i in range(len(normalized_tweet)):\n",
    "    normalized_tweet[i] = ''.join(normalized_tweet[i])    \n",
    "df_tweet['mensajeprocesado'] = normalized_tweet\n",
    "\n",
    "df_tweet.drop(df_tweet.filter(regex=\"Unname\"),axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = df_tweet['text'].apply(processTweet)\n",
    "nb_words = 10000  \n",
    "tk = Tokenizer(num_words=nb_words) #tokenize\n",
    "tk.fit_on_texts(tweet) #tokenize\n",
    "\n",
    "# format your input for the neural net\n",
    "tweets_seq = tk.texts_to_sequences(tweet) # integer encode\n",
    "tweet_array = pad_sequences(tweets_seq, # good to use length it was trained on\n",
    "                            maxlen=39) # Convert to 2-D Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"modeloKerasreg\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 28, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 200)               263200    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 603       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,543,803\n",
      "Trainable params: 1,543,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM_model = load_model('./modelos/LSTM_model.h5')\n",
    "LSTM_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-556ebbc0d06b>:7: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28) for input Tensor(\"embedding_input:0\", shape=(None, 28), dtype=float32), but it was called on an input with incompatible shape (10000, 39).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = len(tweet_array)\n",
    "\n",
    "# for human-friendly printing\n",
    "labels = ['negative', 'positive']\n",
    "\n",
    "# Predict and get output from the model\n",
    "pred= LSTM_model.predict_classes(tweet_array, batch_size)\n",
    "\n",
    "# append predictions to dataframe\n",
    "df_tweet['predictions'] = pred\n",
    "df_tweet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>procesado</th>\n",
       "      <th>Polaridad</th>\n",
       "      <th>Subjetividad</th>\n",
       "      <th>palabras</th>\n",
       "      <th>mensajeprocesado</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negativa</td>\n",
       "      <td>2014943573</td>\n",
       "      <td>Wed Jun 03 03:11:56 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bexodus</td>\n",
       "      <td>@MissScion Fell asleep around 9p last night wo...</td>\n",
       "      <td>['fell', 'asleep', 'around', 'last', 'night', ...</td>\n",
       "      <td>-0.016667</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>26</td>\n",
       "      <td>MissScion Fell asleep around  p last night wo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>2001267352</td>\n",
       "      <td>Tue Jun 02 00:20:21 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>primetheus</td>\n",
       "      <td>sigh ... what i would give to be on a beach so...</td>\n",
       "      <td>['sigh', 'would', 'give', 'beach', 'somewhere']</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>sigh     what i would give to be on a beach so...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>2178458794</td>\n",
       "      <td>Mon Jun 15 07:43:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>emfeha</td>\n",
       "      <td>Check my new twitter background. Portfolio v5 ...</td>\n",
       "      <td>['check', 'new', 'twitter', 'background', 'por...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>12</td>\n",
       "      <td>Check my new twitter background  Portfolio v  ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>1792192715</td>\n",
       "      <td>Wed May 13 22:24:34 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Alex_Manchester</td>\n",
       "      <td>@collabguy Very interesting.  I can't touch ty...</td>\n",
       "      <td>['interesting', 'touch', 'type', 'properly', '...</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>23</td>\n",
       "      <td>collabguy Very interesting   I can t touch ty...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>2302731266</td>\n",
       "      <td>Tue Jun 23 17:13:02 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>YarnThing</td>\n",
       "      <td>@iambrianna did you leave it on my cell? I can...</td>\n",
       "      <td>['leave', 'cell', 'find']</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>iambrianna did you leave it on my cell  I can...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target         ids                          date      flag  \\\n",
       "0  Negativa  2014943573  Wed Jun 03 03:11:56 PDT 2009  NO_QUERY   \n",
       "6   Neutral  2001267352  Tue Jun 02 00:20:21 PDT 2009  NO_QUERY   \n",
       "7  Positiva  2178458794  Mon Jun 15 07:43:55 PDT 2009  NO_QUERY   \n",
       "8  Positiva  1792192715  Wed May 13 22:24:34 PDT 2009  NO_QUERY   \n",
       "9   Neutral  2302731266  Tue Jun 23 17:13:02 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \\\n",
       "0          bexodus  @MissScion Fell asleep around 9p last night wo...   \n",
       "6       primetheus  sigh ... what i would give to be on a beach so...   \n",
       "7           emfeha  Check my new twitter background. Portfolio v5 ...   \n",
       "8  Alex_Manchester  @collabguy Very interesting.  I can't touch ty...   \n",
       "9        YarnThing  @iambrianna did you leave it on my cell? I can...   \n",
       "\n",
       "                                           procesado  Polaridad  Subjetividad  \\\n",
       "0  ['fell', 'asleep', 'around', 'last', 'night', ...  -0.016667      0.488889   \n",
       "6    ['sigh', 'would', 'give', 'beach', 'somewhere']   0.000000      0.000000   \n",
       "7  ['check', 'new', 'twitter', 'background', 'por...   0.136364      0.454545   \n",
       "8  ['interesting', 'touch', 'type', 'properly', '...   0.233333      0.400000   \n",
       "9                          ['leave', 'cell', 'find']   0.000000      0.000000   \n",
       "\n",
       "   palabras                                   mensajeprocesado  predictions  \n",
       "0        26   MissScion Fell asleep around  p last night wo...            2  \n",
       "6        12  sigh     what i would give to be on a beach so...            2  \n",
       "7        12  Check my new twitter background  Portfolio v  ...            2  \n",
       "8        23   collabguy Very interesting   I can t touch ty...            2  \n",
       "9        15   iambrianna did you leave it on my cell  I can...            2  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet[df_tweet['predictions'] == 2].head(5) # negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>procesado</th>\n",
       "      <th>Polaridad</th>\n",
       "      <th>Subjetividad</th>\n",
       "      <th>palabras</th>\n",
       "      <th>mensajeprocesado</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>1971796339</td>\n",
       "      <td>Sat May 30 07:55:06 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>sazmataz_x</td>\n",
       "      <td>@katie_andhearts going in town later to get my...</td>\n",
       "      <td>['going', 'town', 'late', 'get', 'prom', 'shoe...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.65</td>\n",
       "      <td>14</td>\n",
       "      <td>katie andhearts going in town later to get my...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>1978132662</td>\n",
       "      <td>Sat May 30 22:31:29 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Deasoy</td>\n",
       "      <td>happy day</td>\n",
       "      <td>['happy', 'day']</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>happy day</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negativa</td>\n",
       "      <td>1679901725</td>\n",
       "      <td>Sat May 02 10:26:43 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>SashaPanda</td>\n",
       "      <td>Tummy Hurts  Stupid Stress</td>\n",
       "      <td>['tummy', 'hurts', 'stupid', 'stress']</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>Tummy Hurts  Stupid Stress</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>2055154954</td>\n",
       "      <td>Sat Jun 06 08:48:06 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LianeGentrySkye</td>\n",
       "      <td>@jodywallace  Are you at the LF event?  I have...</td>\n",
       "      <td>['event', 'seen']</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11</td>\n",
       "      <td>jodywallace  Are you at the LF event   I have...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>2066500448</td>\n",
       "      <td>Sun Jun 07 10:38:18 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>darkrumblog</td>\n",
       "      <td>@Fleshworks Excellent, very good indeed!  Am p...</td>\n",
       "      <td>['excellent', 'good', 'indeed', 'posting']</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.80</td>\n",
       "      <td>9</td>\n",
       "      <td>Fleshworks Excellent  very good indeed   Am p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target         ids                          date      flag  \\\n",
       "1  Positiva  1971796339  Sat May 30 07:55:06 PDT 2009  NO_QUERY   \n",
       "2  Positiva  1978132662  Sat May 30 22:31:29 PDT 2009  NO_QUERY   \n",
       "3  Negativa  1679901725  Sat May 02 10:26:43 PDT 2009  NO_QUERY   \n",
       "4   Neutral  2055154954  Sat Jun 06 08:48:06 PDT 2009  NO_QUERY   \n",
       "5  Positiva  2066500448  Sun Jun 07 10:38:18 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \\\n",
       "1       sazmataz_x  @katie_andhearts going in town later to get my...   \n",
       "2           Deasoy                                         happy day    \n",
       "3       SashaPanda                         Tummy Hurts  Stupid Stress   \n",
       "4  LianeGentrySkye  @jodywallace  Are you at the LF event?  I have...   \n",
       "5      darkrumblog  @Fleshworks Excellent, very good indeed!  Am p...   \n",
       "\n",
       "                                           procesado  Polaridad  Subjetividad  \\\n",
       "1  ['going', 'town', 'late', 'get', 'prom', 'shoe...       0.25          0.65   \n",
       "2                                   ['happy', 'day']       0.80          1.00   \n",
       "3             ['tummy', 'hurts', 'stupid', 'stress']      -0.80          1.00   \n",
       "4                                  ['event', 'seen']       0.00          0.00   \n",
       "5         ['excellent', 'good', 'indeed', 'posting']       0.85          0.80   \n",
       "\n",
       "   palabras                                   mensajeprocesado  predictions  \n",
       "1        14   katie andhearts going in town later to get my...            1  \n",
       "2         2                                         happy day             1  \n",
       "3         4                         Tummy Hurts  Stupid Stress            1  \n",
       "4        11   jodywallace  Are you at the LF event   I have...            1  \n",
       "5         9   Fleshworks Excellent  very good indeed   Am p...            1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet[df_tweet['predictions'] == 1].head(5) # neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>procesado</th>\n",
       "      <th>Polaridad</th>\n",
       "      <th>Subjetividad</th>\n",
       "      <th>palabras</th>\n",
       "      <th>mensajeprocesado</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>2047799782</td>\n",
       "      <td>Fri Jun 05 14:11:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Chicagogirl1996</td>\n",
       "      <td>The most wonderful thing happend today are car...</td>\n",
       "      <td>['wonderful', 'thing', 'happend', 'today', 'ca...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>The most wonderful thing happend today are car...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>1881440898</td>\n",
       "      <td>Fri May 22 04:40:20 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>KathrynBriggs</td>\n",
       "      <td>Starting to panic about impending first semest...</td>\n",
       "      <td>['starting', 'panic', 'impending', 'first', 's...</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>22</td>\n",
       "      <td>Starting to panic about impending first semest...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>2072090964</td>\n",
       "      <td>Sun Jun 07 20:23:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>janicepcheng</td>\n",
       "      <td>@aronsolomon I love how you always get my name...</td>\n",
       "      <td>['love', 'always', 'get', 'names', 'wrong', 'j...</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>21</td>\n",
       "      <td>aronsolomon I love how you always get my name...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>2044347056</td>\n",
       "      <td>Fri Jun 05 09:13:30 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RaqC</td>\n",
       "      <td>Up and running early! Headed 2 court 2 get a d...</td>\n",
       "      <td>['running', 'early', 'headed', 'court', 'get',...</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>27</td>\n",
       "      <td>Up and running early  Headed   court   get a d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Negativa</td>\n",
       "      <td>2204027282</td>\n",
       "      <td>Wed Jun 17 01:08:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>williams1993</td>\n",
       "      <td>Feels like crap! Im such an eejit sometimes!</td>\n",
       "      <td>['feels', 'like', 'crap', 'eejit', 'sometimes']</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>8</td>\n",
       "      <td>Feels like crap  Im such an eejit sometimes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Negativa</td>\n",
       "      <td>2014795190</td>\n",
       "      <td>Wed Jun 03 02:42:46 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>aussiegirl_1996</td>\n",
       "      <td>Got the WORST migraine at skool 2day.A bit dra...</td>\n",
       "      <td>['got', 'bad', 'migraine', 'skool', 'bit', 'dr...</td>\n",
       "      <td>-0.344444</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>18</td>\n",
       "      <td>Got the WORST migraine at skool  day A bit dra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>2048072672</td>\n",
       "      <td>Fri Jun 05 14:37:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>krystyl</td>\n",
       "      <td>For a low low price of $35,000.00 you too can ...</td>\n",
       "      <td>['low', 'low', 'price', 'hammock', 'cool', 'bu...</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>26</td>\n",
       "      <td>For a low low price of            you too can ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>1983596849</td>\n",
       "      <td>Sun May 31 13:27:46 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>allora</td>\n",
       "      <td>@Gastro1 just checked out their site..the clos...</td>\n",
       "      <td>['checked', 'site', 'close', 'shop', 'berlin',...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>Gastro  just checked out their site  the clos...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Negativa</td>\n",
       "      <td>1684849864</td>\n",
       "      <td>Sat May 02 22:14:18 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>KBernice</td>\n",
       "      <td>PACQUIAO! Hatton got owned! Second round too!</td>\n",
       "      <td>['pacquiao', 'hatton', 'got', 'owned', 'second...</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>7</td>\n",
       "      <td>PACQUIAO  Hatton got owned  Second round too</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Negativa</td>\n",
       "      <td>2066820884</td>\n",
       "      <td>Sun Jun 07 11:13:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Alica87</td>\n",
       "      <td>@bubblything Dear, I'm so sorry, I forgot that...</td>\n",
       "      <td>['dear', 'sorry', 'forgot', 'understand', 'ger...</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>17</td>\n",
       "      <td>bubblything Dear  I m so sorry  I forgot that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      target         ids                          date      flag  \\\n",
       "10  Positiva  2047799782  Fri Jun 05 14:11:57 PDT 2009  NO_QUERY   \n",
       "19  Positiva  1881440898  Fri May 22 04:40:20 PDT 2009  NO_QUERY   \n",
       "20  Positiva  2072090964  Sun Jun 07 20:23:09 PDT 2009  NO_QUERY   \n",
       "24  Positiva  2044347056  Fri Jun 05 09:13:30 PDT 2009  NO_QUERY   \n",
       "29  Negativa  2204027282  Wed Jun 17 01:08:03 PDT 2009  NO_QUERY   \n",
       "33  Negativa  2014795190  Wed Jun 03 02:42:46 PDT 2009  NO_QUERY   \n",
       "38  Positiva  2048072672  Fri Jun 05 14:37:13 PDT 2009  NO_QUERY   \n",
       "46  Positiva  1983596849  Sun May 31 13:27:46 PDT 2009  NO_QUERY   \n",
       "51  Negativa  1684849864  Sat May 02 22:14:18 PDT 2009  NO_QUERY   \n",
       "54  Negativa  2066820884  Sun Jun 07 11:13:55 PDT 2009  NO_QUERY   \n",
       "\n",
       "               user                                               text  \\\n",
       "10  Chicagogirl1996  The most wonderful thing happend today are car...   \n",
       "19    KathrynBriggs  Starting to panic about impending first semest...   \n",
       "20     janicepcheng  @aronsolomon I love how you always get my name...   \n",
       "24             RaqC  Up and running early! Headed 2 court 2 get a d...   \n",
       "29     williams1993      Feels like crap! Im such an eejit sometimes!    \n",
       "33  aussiegirl_1996  Got the WORST migraine at skool 2day.A bit dra...   \n",
       "38          krystyl  For a low low price of $35,000.00 you too can ...   \n",
       "46           allora  @Gastro1 just checked out their site..the clos...   \n",
       "51         KBernice     PACQUIAO! Hatton got owned! Second round too!    \n",
       "54          Alica87  @bubblything Dear, I'm so sorry, I forgot that...   \n",
       "\n",
       "                                            procesado  Polaridad  \\\n",
       "10  ['wonderful', 'thing', 'happend', 'today', 'ca...   1.000000   \n",
       "19  ['starting', 'panic', 'impending', 'first', 's...   0.150000   \n",
       "20  ['love', 'always', 'get', 'names', 'wrong', 'j...   0.360000   \n",
       "24  ['running', 'early', 'headed', 'court', 'get',...   0.450000   \n",
       "29    ['feels', 'like', 'crap', 'eejit', 'sometimes']  -0.800000   \n",
       "33  ['got', 'bad', 'migraine', 'skool', 'bit', 'dr...  -0.344444   \n",
       "38  ['low', 'low', 'price', 'hammock', 'cool', 'bu...   0.116667   \n",
       "46  ['checked', 'site', 'close', 'shop', 'berlin',...   0.100000   \n",
       "51  ['pacquiao', 'hatton', 'got', 'owned', 'second...  -0.100000   \n",
       "54  ['dear', 'sorry', 'forgot', 'understand', 'ger...  -0.250000   \n",
       "\n",
       "    Subjetividad  palabras                                   mensajeprocesado  \\\n",
       "10      1.000000        10  The most wonderful thing happend today are car...   \n",
       "19      0.211111        22  Starting to panic about impending first semest...   \n",
       "20      0.800000        21   aronsolomon I love how you always get my name...   \n",
       "24      0.525000        27  Up and running early  Headed   court   get a d...   \n",
       "29      0.800000         8      Feels like crap  Im such an eejit sometimes     \n",
       "33      0.522222        18  Got the WORST migraine at skool  day A bit dra...   \n",
       "38      0.416667        26  For a low low price of            you too can ...   \n",
       "46      1.000000        14   Gastro  just checked out their site  the clos...   \n",
       "51      0.200000         7     PACQUIAO  Hatton got owned  Second round too     \n",
       "54      0.500000        17   bubblything Dear  I m so sorry  I forgot that...   \n",
       "\n",
       "    predictions  \n",
       "10            0  \n",
       "19            0  \n",
       "20            0  \n",
       "24            0  \n",
       "29            0  \n",
       "33            0  \n",
       "38            0  \n",
       "46            0  \n",
       "51            0  \n",
       "54            0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet[df_tweet['predictions'] == 0].head(10) # positivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of positve tagged sentences is:  3625\n",
      "number of neutral tagged sentences is: 4663\n",
      "number of negative tagged sentences is: 1712\n",
      "total length of the data is:            10000\n"
     ]
    }
   ],
   "source": [
    "positives = df_tweet['predictions'][df_tweet.predictions == 2]\n",
    "neutral = df_tweet['predictions'][df_tweet.predictions == 1]\n",
    "negatives = df_tweet['predictions'][df_tweet.predictions == 0]\n",
    "\n",
    "print('number of positve tagged sentences is:  {}'.format(len(positives)))\n",
    "print('number of neutral tagged sentences is: {}'.format(len(neutral)))\n",
    "print('number of negative tagged sentences is: {}'.format(len(negatives)))\n",
    "print('total length of the data is:            {}'.format(df_tweet.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet.to_csv('./output/df_tweets_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4663\n",
       "2    3625\n",
       "0    1712\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
